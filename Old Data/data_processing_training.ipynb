{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperiencePool:\n",
    "    \"\"\"\n",
    "    Experience pool for collecting trajectories.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "    def add(self, state, action, reward, done):\n",
    "        self.states.append(state)  # sometimes state is also called obs (observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "def pre_process_extract():\n",
    "    # Open the input file and output file in the same context\n",
    "    with open('llmrawdata.txt', 'r') as infile, open('lmprocesseddata.txt', 'w') as outfile:\n",
    "        for line in infile:\n",
    "            if 'l4s_ecn_marking-start' in line:\n",
    "                # Remove the prefix 'l4s_ecn_marking-start,' and trailing ' end'\n",
    "                parts = line.split(\"-\")\n",
    "                if len(parts) > 1:\n",
    "                    content = parts[1].strip()  # Remove any leading/trailing whitespace\n",
    "                    if content.endswith('end'):\n",
    "                        # Write the content to the output file, stripping the 'end' part\n",
    "                        outfile.write(content[6:-4] + '\\n')\n",
    "    import pandas as pd\n",
    "\n",
    "    # Define the column list as you provided\n",
    "    column_list = [\n",
    "        \"queue_type\",                   # q->queue_type\n",
    "        \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "        \"tupdate\",                      # pprms->tupdate\n",
    "        \"max_burst\",                    # pprms->max_burst\n",
    "        \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "        \"alpha_coefficient\",            # pprms->alpha\n",
    "        \"beta_coefficient\",             # pprms->beta\n",
    "        \"flags\",                        # pprms->flags\n",
    "        \"burst_allowance\",              # pst->burst_allowance\n",
    "        \"drop_probability\",             # pst->drop_prob\n",
    "        \"current_queue_delay\",          # pst->current_qdelay\n",
    "        \"previous_queue_delay\",         # pst->qdelay_old\n",
    "        \"accumulated_probability\",      # pst->accu_prob\n",
    "        \"measurement_start_time\",       # pst->measurement_start\n",
    "        \"average_dequeue_time\",         # pst->avg_dq_time\n",
    "        \"dequeue_count\",                # pst->dq_count\n",
    "        \"status_flags\",                 # pst->sflags\n",
    "        \"total_packets\",                # q->stats.tot_pkts\n",
    "        \"total_bytes\",                  # q->stats.tot_bytes\n",
    "        \"queue_length\",                 # q->stats.length\n",
    "        \"length_in_bytes\",              # q->stats.len_bytes\n",
    "        \"total_drops\",                  # q->stats.drops\n",
    "        \"packet_length\",                # q->packet_length\n",
    "        \"dequeue_action\"                # dequeue_action\n",
    "    ]\n",
    "\n",
    "    # Read the CSV, skipping lines with too many columns\n",
    "    df = pd.read_csv(\n",
    "        \"lmprocesseddata.txt\", \n",
    "        names=column_list, \n",
    "        header=None, \n",
    "        on_bad_lines='skip',  # Skip lines with too many fields\n",
    "        usecols=range(len(column_list))  # Ensure we only read the correct number of columns\n",
    "    )\n",
    "\n",
    "    # # Display the dataframe to check if it loaded correctly\n",
    "    # print(df.head())\n",
    "    # Drop columns that contain 'pprms' in their name\n",
    "    columns_to_drop = [\n",
    "        \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "        \"tupdate\",                      # pprms->tupdate\n",
    "        \"max_burst\",                    # pprms->max_burst\n",
    "        \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "        \"alpha_coefficient\",            # pprms->alpha\n",
    "        \"beta_coefficient\",             # pprms->beta\n",
    "        \"flags\",                        # pprms->flags\n",
    "        ]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    df['dequeue_action']=df['dequeue_action']-1\n",
    "    # df['dequeue_action'].unique()\n",
    "    # df['dequeue_action'].value_counts()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pre_process_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_df(df, trim_percent=0.2):\n",
    "    # Calculate the number of rows to trim (8% of total rows)\n",
    "    print(\"Old Shape\",df.shape)\n",
    "    rows_to_trim = int(len(df) * trim_percent)\n",
    "\n",
    "    # Trim the top 5% of the DataFrame\n",
    "    trimmed_df = df.iloc[rows_to_trim:]\n",
    "\n",
    "    # Reset the index of the trimmed DataFrame\n",
    "    trimmed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Display the trimmed DataFrame\n",
    "    print(\"New Shape\",trimmed_df.shape)\n",
    "    df = trimmed_df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trim_df(df,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen_Exp_Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_exp_pool():\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "\n",
    "    pickle_save_path = 'exp_pool_l4s_train.pkl'\n",
    "    train_exp_percent = 0.2\n",
    "\n",
    "    # Define the list of columns to include\n",
    "    columns_to_use = [\n",
    "        'queue_type', \n",
    "        'burst_allowance',\n",
    "        'drop_probability',\n",
    "        'current_queue_delay',\n",
    "        'accumulated_probability',\n",
    "        'average_dequeue_time',\n",
    "        'length_in_bytes',\n",
    "        'total_drops', \n",
    "        'packet_length'\n",
    "    ]\n",
    "\n",
    "    # Variable to store the window size (number of rows to collect)\n",
    "    window_size = 5\n",
    "\n",
    "    # Initialize the experience pool\n",
    "    exp_pool = ExperiencePool()\n",
    "\n",
    "    # Initialize variables for tracking previous action and accumulating rows\n",
    "    prev_action = None\n",
    "\n",
    "\n",
    "    # Iterate through each row and update the experience pool\n",
    "    for index, row in df.iterrows():\n",
    "        state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "        current_action = row['dequeue_action']\n",
    "        \n",
    "        if prev_action is not None and current_action != prev_action:\n",
    "         \n",
    "            # If there's a change in action, collect the last 'window_size' rows\n",
    "            start_index = max(0, index - window_size)  # Ensure we don't go below 0\n",
    "            end_index = index  # Exclude the current row (where the action changed)\n",
    "\n",
    "            # Select the last 'window_size' rows and add them to the experience pool\n",
    "            selected_rows = df.iloc[start_index:end_index]\n",
    "            for _, selected_row in selected_rows.iterrows():\n",
    "                state = np.array(selected_row[columns_to_use], dtype=np.float32)\n",
    "                exp_pool.add(state=state, action=selected_row['dequeue_action'], reward=selected_row['current_queue_delay'], done=0)\n",
    "                    \n",
    "        if index > df.shape[0] * train_exp_percent:\n",
    "            break;\n",
    "        \n",
    "        # Update the previous action\n",
    "        prev_action = current_action\n",
    "\n",
    "    # Save the experience pool\n",
    "    with open(pickle_save_path, 'wb') as f:\n",
    "        pickle.dump(exp_pool, f)\n",
    "\n",
    "    print(f\"Done. Experience pool saved at: {pickle_save_path}\")\n",
    "\n",
    "    print(\"len(actions)\",len(exp_pool.actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_eval_exp_pool():\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "\n",
    "    pickle_save_path = 'exp_pool_l4s_eval.pkl'\n",
    "    eval_exp_percent = 0.02\n",
    "\n",
    "    # Define the list of columns to include\n",
    "    columns_to_use = [\n",
    "        'queue_type', \n",
    "        'burst_allowance',\n",
    "        'drop_probability',\n",
    "        'current_queue_delay',\n",
    "        'accumulated_probability',\n",
    "        'average_dequeue_time',\n",
    "        'length_in_bytes',\n",
    "        'total_drops', \n",
    "        'packet_length'\n",
    "    ]\n",
    "\n",
    "    # Variable to store the window size (number of rows to collect)\n",
    "    window_size = 5\n",
    "\n",
    "    # Initialize the experience pool\n",
    "    exp_pool = ExperiencePool()\n",
    "\n",
    "    # Iterate through each row and update the experience pool\n",
    "    for index, row in df.iterrows():\n",
    "        state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "        exp_pool.add(state=state, action=row['dequeue_action'], reward=row['current_queue_delay'], done=0)                    \n",
    "        if index > df.shape[0] * eval_exp_percent:\n",
    "            break;\n",
    "\n",
    "    # Save the experience pool\n",
    "    with open(pickle_save_path, 'wb') as f:\n",
    "        pickle.dump(exp_pool, f)\n",
    "\n",
    "    print(f\"Done. Experience pool saved at: {pickle_save_path}\")\n",
    "\n",
    "    print(\"len(actions)\",len(exp_pool.actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_exp_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_eval_exp_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Delete the output file after processing\n",
    "os.remove('lmprocesseddata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# # Define the list of columns to include\n",
    "# columns_to_use = [\n",
    "#     'queue_type', \n",
    "#     'burst_allowance',\n",
    "#     'drop_probability',\n",
    "#     'current_queue_delay',\n",
    "#     'accumulated_probability',\n",
    "#     'average_dequeue_time',\n",
    "#     'length_in_bytes',\n",
    "#     'total_drops', \n",
    "#     'packet_length'\n",
    "# ]\n",
    "\n",
    "# # Variable to store the window size (number of rows to collect)\n",
    "# window_size = 5\n",
    "\n",
    "# # Initialize the experience pool\n",
    "# exp_pool = ExperiencePool()\n",
    "\n",
    "# # Initialize variables for tracking previous action and accumulating rows\n",
    "# prev_action = None\n",
    "# row_buffer = []\n",
    "# count=0\n",
    "\n",
    "# # Iterate through each row and update the experience pool\n",
    "# for index, row in df.iterrows():\n",
    "#     state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "#     current_action = row['dequeue_action']\n",
    "    \n",
    "#     if prev_action is not None and current_action != prev_action:\n",
    "#         count+=1\n",
    "#         # If there's a change in action, collect the last 'window_size' rows\n",
    "#         start_index = max(0, index - window_size)  # Ensure we don't go below 0\n",
    "#         end_index = index  # Exclude the current row (where the action changed)\n",
    "\n",
    "#         # Select the last 'window_size' rows and add them to the experience pool\n",
    "#         selected_rows = df.iloc[start_index:end_index]\n",
    "#         for _, selected_row in selected_rows.iterrows():\n",
    "#             state = np.array(selected_row[columns_to_use], dtype=np.float32)\n",
    "#             exp_pool.add(state=state, action=selected_row['dequeue_action'], reward=selected_row['current_queue_delay'], done=0)\n",
    "        \n",
    "#         # Clear buffer as we only want the last 50 rows at each action change\n",
    "#         row_buffer = []\n",
    "\n",
    "#     # Add current row to the buffer (though it won't be used in the final experience pool)\n",
    "#     row_buffer.append(row)\n",
    "#     if index > df.shape[0] *0.2:\n",
    "#         break;\n",
    "    \n",
    "#     # Update the previous action\n",
    "#     prev_action = current_action\n",
    "\n",
    "# # Save the experience pool\n",
    "# pickle_save_path = 'exp_pool_l4s_train.pkl'\n",
    "# with open(pickle_save_path, 'wb') as f:\n",
    "#     pickle.dump(exp_pool, f)\n",
    "\n",
    "# print(f\"Done. Experience pool saved at: {pickle_save_path}\")\n",
    "# import os\n",
    "# # Delete the output file after processing\n",
    "# os.remove('lmprocesseddata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def discount_returns(rewards, gamma, scale):\n",
    "    returns = [0 for _ in range(len(rewards))]\n",
    "    returns[-1] = rewards[-1]\n",
    "    for i in reversed(range(len(rewards) - 1)):\n",
    "        returns[i] = rewards[i] + gamma * returns[i + 1]\n",
    "    for i in range(len(returns)):\n",
    "        returns[i] /= scale  # scale down return\n",
    "    return returns\n",
    "\n",
    "\n",
    "class ExperienceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class that wraps the experience pool.\n",
    "    \"\"\"\n",
    "    def __init__(self, exp_pool, gamma=1., scale=10, max_length=30, sample_step=None) -> None:\n",
    "        \"\"\"\n",
    "        :param exp_pool: the experience pool\n",
    "        :param gamma: the reward discounted factor\n",
    "        :param scale: the factor to scale the return\n",
    "        :param max_length: the w value in our paper, see the paper for details.\n",
    "        \"\"\"\n",
    "        if sample_step is None:\n",
    "            sample_step = max_length\n",
    "\n",
    "        self.exp_pool = exp_pool\n",
    "        self.exp_pool_size = len(exp_pool)\n",
    "        self.gamma = gamma\n",
    "        self.scale = scale\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.returns = []\n",
    "        self.timesteps = []\n",
    "        self.rewards = []\n",
    "\n",
    "        self.exp_dataset_info = {}\n",
    "\n",
    "        self._normalize_rewards()\n",
    "        self._compute_returns()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_action': max(self.actions),\n",
    "            'min_action': min(self.actions)\n",
    "        })\n",
    "\n",
    "        self.dataset_indices = list(range(0, self.exp_pool_size - max_length + 1, min(sample_step, max_length)))\n",
    "    \n",
    "    def sample_batch(self, batch_size=1, batch_indices=None):\n",
    "        \"\"\"\n",
    "        Sample a batch of data from the experience pool.\n",
    "        :param batch_size: the size of a batch. For CJS task, batch_size should be set to 1 due to the unstructural data format.\n",
    "        \"\"\"\n",
    "        if batch_indices is None:\n",
    "            batch_indices = np.random.choice(len(self.dataset_indices), size=batch_size)\n",
    "        batch_states, batch_actions, batch_returns, batch_timesteps = [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            states, actions, returns, timesteps = self[batch_indices[i]]\n",
    "            batch_states.append(states)\n",
    "            batch_actions.append(actions)\n",
    "            batch_returns.append(returns)\n",
    "            batch_timesteps.append(timesteps)\n",
    "        return batch_states, batch_actions, batch_returns, batch_timesteps\n",
    "    \n",
    "    @property\n",
    "    def states(self):\n",
    "        return self.exp_pool.states\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self.exp_pool.actions\n",
    "    \n",
    "    @property\n",
    "    def dones(self):\n",
    "        return self.exp_pool.dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start = self.dataset_indices[index]\n",
    "        end = start + self.max_length\n",
    "        return self.states[start:end], self.actions[start:end], self.returns[start:end], self.timesteps[start:end]\n",
    "\n",
    "    def _normalize_rewards(self):\n",
    "        min_reward, max_reward = min(self.exp_pool.rewards), max(self.exp_pool.rewards)\n",
    "        rewards = (np.array(self.exp_pool.rewards) - min_reward) / (max_reward - min_reward)\n",
    "        self.rewards = rewards.tolist()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_reward': max_reward,\n",
    "            'min_reward': min_reward,\n",
    "        })\n",
    "\n",
    "    def _compute_returns(self):\n",
    "        \"\"\"\n",
    "        Compute returns (discounted cumulative rewards)\n",
    "        \"\"\"\n",
    "        episode_start = 0\n",
    "        while episode_start < self.exp_pool_size:\n",
    "            try:\n",
    "                episode_end = self.dones.index(True, episode_start) + 1\n",
    "            except ValueError:\n",
    "                episode_end = self.exp_pool_size\n",
    "            self.returns.extend(discount_returns(self.rewards[episode_start:episode_end], self.gamma, self.scale))\n",
    "            self.timesteps += list(range(episode_end - episode_start))\n",
    "            episode_start = episode_end\n",
    "        assert len(self.returns) == len(self.timesteps)\n",
    "        self.exp_dataset_info.update({\n",
    "            # for normalizing rewards/returns\n",
    "            'max_return': max(self.returns),\n",
    "            'min_return': min(self.returns),\n",
    "\n",
    "            # to help determine the maximum size of timesteps embedding\n",
    "            'min_timestep': min(self.timesteps),\n",
    "            'max_timestep': max(self.timesteps),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dataset = ExperienceDataset(exp_pool, gamma=1.0, scale=1000, max_length=20, sample_step=10)\n",
    "batch_size =1\n",
    "exp_dataset_info = Munch(exp_dataset.exp_dataset_info)\n",
    "dataloader = DataLoader(exp_dataset, batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "    states, actions, returns, timesteps = batch\n",
    "    print(\"Type of first element in states:\", type(states[0]))\n",
    "    print(\"process_batch states type:\",type(states))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for step, batch in enumerate(dataloader):\n",
    "    count+=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
