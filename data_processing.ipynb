{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the input file and output file in the same context\n",
    "# with open('llmrawdata.txt', 'r') as infile, open('lmprocesseddata.txt', 'w') as outfile:\n",
    "#     for line in infile:\n",
    "#         if 'l4s_ecn_marking-start' in line:\n",
    "#             # Remove the prefix 'l4s_ecn_marking-start,' and trailing ' end'\n",
    "#             temp=line.split(\"-\")\n",
    "#             temp1=temp[1]\n",
    "            \n",
    "#             temp1=temp1.split(\",\")\n",
    "#             #print(temp1[-1]==\"end \\n\")\n",
    "#             if(temp1[-1]==\"end \\n\"):\n",
    "#                 outfile.writelines(temp[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input file and output file in the same context\n",
    "with open('llmrawdata.txt', 'r') as infile, open('lmprocesseddata.txt', 'w') as outfile:\n",
    "    for line in infile:\n",
    "        if 'l4s_ecn_marking-start' in line:\n",
    "            # Remove the prefix 'l4s_ecn_marking-start,' and trailing ' end'\n",
    "            parts = line.split(\"-\")\n",
    "            if len(parts) > 1:\n",
    "                content = parts[1].strip()  # Remove any leading/trailing whitespace\n",
    "                if content.endswith('end'):\n",
    "                    # Write the content to the output file, stripping the 'end' part\n",
    "                    outfile.write(content[6:-4] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\n",
    "    \"queue_type\",                   # q->queue_type\n",
    "    \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "    \"tupdate\",                      # pprms->tupdate\n",
    "    \"max_burst\",                    # pprms->max_burst\n",
    "    \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "    \"alpha_coefficient\",            # pprms->alpha\n",
    "    \"beta_coefficient\",             # pprms->beta\n",
    "    \"flags\",                        # pprms->flags\n",
    "    \"burst_allowance\",              # pst->burst_allowance\n",
    "    \"drop_probability\",             # pst->drop_prob\n",
    "    \"current_queue_delay\",          # pst->current_qdelay\n",
    "    \"previous_queue_delay\",         # pst->qdelay_old\n",
    "    \"accumulated_probability\",      # pst->accu_prob\n",
    "    \"measurement_start_time\",       # pst->measurement_start\n",
    "    \"average_dequeue_time\",         # pst->avg_dq_time\n",
    "    \"dequeue_count\",                # pst->dq_count\n",
    "    \"status_flags\",                 # pst->sflags\n",
    "    \"total_packets\",                # q->stats.tot_pkts\n",
    "    \"total_bytes\",                  # q->stats.tot_bytes\n",
    "    \"queue_length\",                 # q->stats.length\n",
    "    \"length_in_bytes\",              # q->stats.len_bytes\n",
    "    \"total_drops\",                  # q->stats.drops\n",
    "    \"dequeue_action\",               # dequeue_action\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"lmprocesseddata.txt\",names=column_list,header=None)\n",
    "\n",
    "# Drop columns that contain 'pprms' in their name\n",
    "columns_to_drop = [\n",
    "    \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "    \"tupdate\",                      # pprms->tupdate\n",
    "    \"max_burst\",                    # pprms->max_burst\n",
    "    \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "    \"alpha_coefficient\",            # pprms->alpha\n",
    "    \"beta_coefficient\",             # pprms->beta\n",
    "    \"flags\",                        # pprms->flags\n",
    "    ]\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"verify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536448 entries, 0 to 536447\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count   Dtype\n",
      "---  ------                   --------------   -----\n",
      " 0   queue_type               536448 non-null  int64\n",
      " 1   burst_allowance          536448 non-null  int64\n",
      " 2   drop_probability         536448 non-null  int64\n",
      " 3   current_queue_delay      536448 non-null  int64\n",
      " 4   previous_queue_delay     536448 non-null  int64\n",
      " 5   accumulated_probability  536448 non-null  int64\n",
      " 6   measurement_start_time   536448 non-null  int64\n",
      " 7   average_dequeue_time     536448 non-null  int64\n",
      " 8   dequeue_count            536448 non-null  int64\n",
      " 9   status_flags             536448 non-null  int64\n",
      " 10  total_packets            536448 non-null  int64\n",
      " 11  total_bytes              536448 non-null  int64\n",
      " 12  queue_length             536448 non-null  int64\n",
      " 13  length_in_bytes          536448 non-null  int64\n",
      " 14  total_drops              536448 non-null  int64\n",
      " 15  dequeue_action           536448 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 65.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dequeue_action']=df['dequeue_action']-1\n",
    "df['dequeue_action'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dequeue_action\n",
       "0    532366\n",
       "1      3394\n",
       "2       688\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dequeue_action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queue_type',\n",
       " 'burst_allowance',\n",
       " 'drop_probability',\n",
       " 'current_queue_delay',\n",
       " 'previous_queue_delay',\n",
       " 'accumulated_probability',\n",
       " 'measurement_start_time',\n",
       " 'average_dequeue_time',\n",
       " 'dequeue_count',\n",
       " 'status_flags',\n",
       " 'total_packets',\n",
       " 'total_bytes',\n",
       " 'queue_length',\n",
       " 'length_in_bytes',\n",
       " 'total_drops',\n",
       " 'dequeue_action']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107289.6"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] *0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Splitting the DataFrame into features and target\n",
    "# X = df.drop('dequeue_action', axis=1)  # Features\n",
    "# y = df['dequeue_action']                # Target variable\n",
    "\n",
    "# # Splitting into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Output the results\n",
    "# print(\"Training Features:\\n\", X_train)\n",
    "# print(\"Testing Features:\\n\", X_test)\n",
    "# print(\"Training Target:\\n\", y_train)\n",
    "# print(\"Testing Target:\\n\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queue_type</th>\n",
       "      <th>burst_allowance</th>\n",
       "      <th>drop_probability</th>\n",
       "      <th>current_queue_delay</th>\n",
       "      <th>previous_queue_delay</th>\n",
       "      <th>accumulated_probability</th>\n",
       "      <th>measurement_start_time</th>\n",
       "      <th>average_dequeue_time</th>\n",
       "      <th>dequeue_count</th>\n",
       "      <th>status_flags</th>\n",
       "      <th>total_packets</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>queue_length</th>\n",
       "      <th>length_in_bytes</th>\n",
       "      <th>total_drops</th>\n",
       "      <th>dequeue_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048030000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>16556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048050000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>16668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048060000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>16884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048070000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>16924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048070000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>16964</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536443</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971502704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>7240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536444</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971522704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>7280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536445</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971542704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>7364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536446</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971562704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>7404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536447</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971562704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>7588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536448 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        queue_type  burst_allowance  drop_probability  current_queue_delay  \\\n",
       "0                0           150000                 0                10000   \n",
       "1                0           150000                 0                    0   \n",
       "2                0           150000                 0                    0   \n",
       "3                0           150000                 0                    0   \n",
       "4                0           150000                 0                    0   \n",
       "...            ...              ...               ...                  ...   \n",
       "536443           0           150000                 0                    0   \n",
       "536444           0           150000                 0                    0   \n",
       "536445           0           150000                 0                    0   \n",
       "536446           0           150000                 0                    0   \n",
       "536447           0           150000                 0                10000   \n",
       "\n",
       "        previous_queue_delay  accumulated_probability  measurement_start_time  \\\n",
       "0                          0                        0              4048030000   \n",
       "1                          0                        0              4048050000   \n",
       "2                          0                        0              4048060000   \n",
       "3                          0                        0              4048070000   \n",
       "4                          0                        0              4048070000   \n",
       "...                      ...                      ...                     ...   \n",
       "536443                     0                        0               971502704   \n",
       "536444                     0                        0               971522704   \n",
       "536445                     0                        0               971542704   \n",
       "536446                     0                        0               971562704   \n",
       "536447                     0                        0               971562704   \n",
       "\n",
       "        average_dequeue_time  dequeue_count  status_flags  total_packets  \\\n",
       "0                          0              0             0             87   \n",
       "1                          0              0             0             88   \n",
       "2                          0              0             0             89   \n",
       "3                          0              0             3             90   \n",
       "4                          0              0             3             91   \n",
       "...                      ...            ...           ...            ...   \n",
       "536443                     0              0             0             31   \n",
       "536444                     0              0             0             32   \n",
       "536445                     0              0             0             33   \n",
       "536446                     0              0             3             34   \n",
       "536447                     0              0             0             35   \n",
       "\n",
       "        total_bytes  queue_length  length_in_bytes  total_drops  \\\n",
       "0             16556             0                0            0   \n",
       "1             16668             0                0            0   \n",
       "2             16884             0                0            0   \n",
       "3             16924             0                0            0   \n",
       "4             16964             1               40            0   \n",
       "...             ...           ...              ...          ...   \n",
       "536443         7240             0                0            0   \n",
       "536444         7280             0                0            0   \n",
       "536445         7364             0                0            0   \n",
       "536446         7404             0                0            0   \n",
       "536447         7588             0                0            0   \n",
       "\n",
       "        dequeue_action  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "536443               0  \n",
       "536444               0  \n",
       "536445               0  \n",
       "536446               0  \n",
       "536447               0  \n",
       "\n",
       "[536448 rows x 16 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ExperiencePool:\n",
    "#     \"\"\"\n",
    "#     Experience pool for collecting trajectories.\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.states = []\n",
    "#         self.actions = []\n",
    "#         self.rewards = []\n",
    "#         self.dones = []\n",
    "\n",
    "#     def add(self, state, action, reward, done):\n",
    "#         self.states.append(state)  # sometime state is also called obs (observation)\n",
    "#         self.actions.append(action)\n",
    "#         self.rewards.append(reward)\n",
    "#         self.dones.append(done)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.states)\n",
    "\n",
    "# # Define the list of columns to include\n",
    "# columns_to_use = [\n",
    "#     'queue_type', \n",
    "#     'burst_allowance',\n",
    "#     'drop_probability',\n",
    "#     'current_queue_delay',\n",
    "#     'accumulated_probability',\n",
    "#     'average_dequeue_time',\n",
    "#     'total_bytes',\n",
    "#     'total_drops'\n",
    "# ]\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# exp_pool = ExperiencePool()\n",
    "# # Initialize the global reward variable\n",
    "# global_reward = 0\n",
    "\n",
    "# # Iterate through each row and update the global reward variable\n",
    "# for index, row in df.iterrows():\n",
    "#     # print(row[columns_to_use])\n",
    "#     state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "#     print(type(state))\n",
    "#     exp_pool.add(state=state, action=row['dequeue_action'], reward=row['current_queue_delay'], done=0)\n",
    "#     break;\n",
    "\n",
    "# pickle_save_path='exp_pool_l4s.pkl'\n",
    "# pickle.dump(exp_pool, open( pickle_save_path, 'wb'))\n",
    "# print(f\"Done. Experience pool saved at:\", pickle_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ExperiencePool:\n",
    "#     \"\"\"\n",
    "#     Experience pool for collecting trajectories.\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.states = []\n",
    "#         self.actions = []\n",
    "#         self.rewards = []\n",
    "#         self.dones = []\n",
    "\n",
    "#     def add(self, state, action, reward, done):\n",
    "#         self.states.append(state)  # sometime state is also called obs (observation)\n",
    "#         self.actions.append(action)\n",
    "#         self.rewards.append(reward)\n",
    "#         self.dones.append(done)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.states)\n",
    "\n",
    "# # Define the list of columns to include\n",
    "# columns_to_use = [\n",
    "#     'queue_type', \n",
    "#     'burst_allowance',\n",
    "#     'drop_probability',\n",
    "#     'current_queue_delay',\n",
    "#     'accumulated_probability',\n",
    "#     'average_dequeue_time',\n",
    "#     'total_bytes',\n",
    "#     'total_drops'\n",
    "# ]\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# exp_pool = ExperiencePool()\n",
    "# # Initialize the global reward variable\n",
    "# global_reward = 0\n",
    "\n",
    "# # Iterate through each row and update the global reward variable\n",
    "# for index, row in df.iterrows():\n",
    "#     state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "#     exp_pool.add(state=state, action=row['dequeue_action'], reward=row['current_queue_delay'], done=0)\n",
    "#     if index > df.shape[0] *0.005:\n",
    "#         break;\n",
    "\n",
    "# pickle_save_path='exp_pool_l4s.pkl'\n",
    "# pickle.dump(exp_pool, open( pickle_save_path, 'wb'))\n",
    "# print(f\"Done. Experience pool saved at:\", pickle_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Experience pool saved at: exp_pool_l4s_train.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class ExperiencePool:\n",
    "    \"\"\"\n",
    "    Experience pool for collecting trajectories.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "    def add(self, state, action, reward, done):\n",
    "        self.states.append(state)  # sometimes state is also called obs (observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "\n",
    "# Define the list of columns to include\n",
    "columns_to_use = [\n",
    "    'queue_type', \n",
    "    'burst_allowance',\n",
    "    'drop_probability',\n",
    "    'current_queue_delay',\n",
    "    'accumulated_probability',\n",
    "    'average_dequeue_time',\n",
    "    'length_in_bytes',\n",
    "    'total_drops'\n",
    "]\n",
    "\n",
    "# Variable to store the window size (number of rows to collect)\n",
    "window_size = 5\n",
    "\n",
    "# Initialize the experience pool\n",
    "exp_pool = ExperiencePool()\n",
    "\n",
    "# Initialize variables for tracking previous action and accumulating rows\n",
    "prev_action = None\n",
    "row_buffer = []\n",
    "count=0\n",
    "\n",
    "# Iterate through each row and update the experience pool\n",
    "for index, row in df.iterrows():\n",
    "    state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "    current_action = row['dequeue_action']\n",
    "    \n",
    "    if prev_action is not None and current_action != prev_action:\n",
    "        count+=1\n",
    "        # If there's a change in action, collect the last 'window_size' rows\n",
    "        start_index = max(0, index - window_size)  # Ensure we don't go below 0\n",
    "        end_index = index  # Exclude the current row (where the action changed)\n",
    "\n",
    "        # Select the last 'window_size' rows and add them to the experience pool\n",
    "        selected_rows = df.iloc[start_index:end_index]\n",
    "        for _, selected_row in selected_rows.iterrows():\n",
    "            state = np.array(selected_row[columns_to_use], dtype=np.float32)\n",
    "            exp_pool.add(state=state, action=selected_row['dequeue_action'], reward=selected_row['current_queue_delay'], done=0)\n",
    "        \n",
    "        # Clear buffer as we only want the last 50 rows at each action change\n",
    "        row_buffer = []\n",
    "\n",
    "    # Add current row to the buffer (though it won't be used in the final experience pool)\n",
    "    row_buffer.append(row)\n",
    "    if index > df.shape[0] *0.06:\n",
    "        break;\n",
    "    \n",
    "    # Update the previous action\n",
    "    prev_action = current_action\n",
    "\n",
    "# Save the experience pool\n",
    "pickle_save_path = 'exp_pool_l4s_train.pkl'\n",
    "with open(pickle_save_path, 'wb') as f:\n",
    "    pickle.dump(exp_pool, f)\n",
    "\n",
    "print(f\"Done. Experience pool saved at: {pickle_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1730"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_pool.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523.25"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10465/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def discount_returns(rewards, gamma, scale):\n",
    "    returns = [0 for _ in range(len(rewards))]\n",
    "    returns[-1] = rewards[-1]\n",
    "    for i in reversed(range(len(rewards) - 1)):\n",
    "        returns[i] = rewards[i] + gamma * returns[i + 1]\n",
    "    for i in range(len(returns)):\n",
    "        returns[i] /= scale  # scale down return\n",
    "    return returns\n",
    "\n",
    "\n",
    "class ExperienceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class that wraps the experience pool.\n",
    "    \"\"\"\n",
    "    def __init__(self, exp_pool, gamma=1., scale=10, max_length=30, sample_step=None) -> None:\n",
    "        \"\"\"\n",
    "        :param exp_pool: the experience pool\n",
    "        :param gamma: the reward discounted factor\n",
    "        :param scale: the factor to scale the return\n",
    "        :param max_length: the w value in our paper, see the paper for details.\n",
    "        \"\"\"\n",
    "        if sample_step is None:\n",
    "            sample_step = max_length\n",
    "\n",
    "        self.exp_pool = exp_pool\n",
    "        self.exp_pool_size = len(exp_pool)\n",
    "        self.gamma = gamma\n",
    "        self.scale = scale\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.returns = []\n",
    "        self.timesteps = []\n",
    "        self.rewards = []\n",
    "\n",
    "        self.exp_dataset_info = {}\n",
    "\n",
    "        self._normalize_rewards()\n",
    "        self._compute_returns()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_action': max(self.actions),\n",
    "            'min_action': min(self.actions)\n",
    "        })\n",
    "\n",
    "        self.dataset_indices = list(range(0, self.exp_pool_size - max_length + 1, min(sample_step, max_length)))\n",
    "    \n",
    "    def sample_batch(self, batch_size=1, batch_indices=None):\n",
    "        \"\"\"\n",
    "        Sample a batch of data from the experience pool.\n",
    "        :param batch_size: the size of a batch. For CJS task, batch_size should be set to 1 due to the unstructural data format.\n",
    "        \"\"\"\n",
    "        if batch_indices is None:\n",
    "            batch_indices = np.random.choice(len(self.dataset_indices), size=batch_size)\n",
    "        batch_states, batch_actions, batch_returns, batch_timesteps = [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            states, actions, returns, timesteps = self[batch_indices[i]]\n",
    "            batch_states.append(states)\n",
    "            batch_actions.append(actions)\n",
    "            batch_returns.append(returns)\n",
    "            batch_timesteps.append(timesteps)\n",
    "        return batch_states, batch_actions, batch_returns, batch_timesteps\n",
    "    \n",
    "    @property\n",
    "    def states(self):\n",
    "        return self.exp_pool.states\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self.exp_pool.actions\n",
    "    \n",
    "    @property\n",
    "    def dones(self):\n",
    "        return self.exp_pool.dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start = self.dataset_indices[index]\n",
    "        end = start + self.max_length\n",
    "        return self.states[start:end], self.actions[start:end], self.returns[start:end], self.timesteps[start:end]\n",
    "\n",
    "    def _normalize_rewards(self):\n",
    "        min_reward, max_reward = min(self.exp_pool.rewards), max(self.exp_pool.rewards)\n",
    "        rewards = (np.array(self.exp_pool.rewards) - min_reward) / (max_reward - min_reward)\n",
    "        self.rewards = rewards.tolist()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_reward': max_reward,\n",
    "            'min_reward': min_reward,\n",
    "        })\n",
    "\n",
    "    def _compute_returns(self):\n",
    "        \"\"\"\n",
    "        Compute returns (discounted cumulative rewards)\n",
    "        \"\"\"\n",
    "        episode_start = 0\n",
    "        while episode_start < self.exp_pool_size:\n",
    "            try:\n",
    "                episode_end = self.dones.index(True, episode_start) + 1\n",
    "            except ValueError:\n",
    "                episode_end = self.exp_pool_size\n",
    "            self.returns.extend(discount_returns(self.rewards[episode_start:episode_end], self.gamma, self.scale))\n",
    "            self.timesteps += list(range(episode_end - episode_start))\n",
    "            episode_start = episode_end\n",
    "        assert len(self.returns) == len(self.timesteps)\n",
    "        self.exp_dataset_info.update({\n",
    "            # for normalizing rewards/returns\n",
    "            'max_return': max(self.returns),\n",
    "            'min_return': min(self.returns),\n",
    "\n",
    "            # to help determine the maximum size of timesteps embedding\n",
    "            'min_timestep': min(self.timesteps),\n",
    "            'max_timestep': max(self.timesteps),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first element in states: <class 'torch.Tensor'>\n",
      "process_batch states type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "exp_dataset = ExperienceDataset(exp_pool, gamma=1.0, scale=1000, max_length=20, sample_step=10)\n",
    "batch_size =1\n",
    "exp_dataset_info = Munch(exp_dataset.exp_dataset_info)\n",
    "dataloader = DataLoader(exp_dataset, batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "    states, actions, returns, timesteps = batch\n",
    "    print(\"Type of first element in states:\", type(states[0]))\n",
    "    print(\"process_batch states type:\",type(states))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for step, batch in enumerate(dataloader):\n",
    "    count+=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vizenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
