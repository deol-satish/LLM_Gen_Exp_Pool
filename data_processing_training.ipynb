{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input file and output file in the same context\n",
    "with open('llmrawdata.txt', 'r') as infile, open('lmprocesseddata.txt', 'w') as outfile:\n",
    "    for line in infile:\n",
    "        if 'l4s_ecn_marking-start' in line:\n",
    "            # Remove the prefix 'l4s_ecn_marking-start,' and trailing ' end'\n",
    "            parts = line.split(\"-\")\n",
    "            if len(parts) > 1:\n",
    "                content = parts[1].strip()  # Remove any leading/trailing whitespace\n",
    "                if content.endswith('end'):\n",
    "                    # Write the content to the output file, stripping the 'end' part\n",
    "                    outfile.write(content[6:-4] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\n",
    "    \"queue_type\",                   # q->queue_type\n",
    "    \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "    \"tupdate\",                      # pprms->tupdate\n",
    "    \"max_burst\",                    # pprms->max_burst\n",
    "    \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "    \"alpha_coefficient\",            # pprms->alpha\n",
    "    \"beta_coefficient\",             # pprms->beta\n",
    "    \"flags\",                        # pprms->flags\n",
    "    \"burst_allowance\",              # pst->burst_allowance\n",
    "    \"drop_probability\",             # pst->drop_prob\n",
    "    \"current_queue_delay\",          # pst->current_qdelay\n",
    "    \"previous_queue_delay\",         # pst->qdelay_old\n",
    "    \"accumulated_probability\",      # pst->accu_prob\n",
    "    \"measurement_start_time\",       # pst->measurement_start\n",
    "    \"average_dequeue_time\",         # pst->avg_dq_time\n",
    "    \"dequeue_count\",                # pst->dq_count\n",
    "    \"status_flags\",                 # pst->sflags\n",
    "    \"total_packets\",                # q->stats.tot_pkts\n",
    "    \"total_bytes\",                  # q->stats.tot_bytes\n",
    "    \"queue_length\",                 # q->stats.length\n",
    "    \"length_in_bytes\",              # q->stats.len_bytes\n",
    "    \"total_drops\",                  # q->stats.drops\n",
    "    \"dequeue_action\",               # dequeue_action\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"lmprocesseddata.txt\",names=column_list,header=None)\n",
    "\n",
    "# Drop columns that contain 'pprms' in their name\n",
    "columns_to_drop = [\n",
    "    \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "    \"tupdate\",                      # pprms->tupdate\n",
    "    \"max_burst\",                    # pprms->max_burst\n",
    "    \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "    \"alpha_coefficient\",            # pprms->alpha\n",
    "    \"beta_coefficient\",             # pprms->beta\n",
    "    \"flags\",                        # pprms->flags\n",
    "    ]\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536439 entries, 0 to 536438\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count   Dtype\n",
      "---  ------                   --------------   -----\n",
      " 0   queue_type               536439 non-null  int64\n",
      " 1   burst_allowance          536439 non-null  int64\n",
      " 2   drop_probability         536439 non-null  int64\n",
      " 3   current_queue_delay      536439 non-null  int64\n",
      " 4   previous_queue_delay     536439 non-null  int64\n",
      " 5   accumulated_probability  536439 non-null  int64\n",
      " 6   measurement_start_time   536439 non-null  int64\n",
      " 7   average_dequeue_time     536439 non-null  int64\n",
      " 8   dequeue_count            536439 non-null  int64\n",
      " 9   status_flags             536439 non-null  int64\n",
      " 10  total_packets            536439 non-null  int64\n",
      " 11  total_bytes              536439 non-null  int64\n",
      " 12  queue_length             536439 non-null  int64\n",
      " 13  length_in_bytes          536439 non-null  int64\n",
      " 14  total_drops              536439 non-null  int64\n",
      " 15  dequeue_action           536439 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 65.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dequeue_action\n",
       "0    532357\n",
       "1      3394\n",
       "2       688\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dequeue_action']=df['dequeue_action']-1\n",
    "df['dequeue_action'].unique()\n",
    "df['dequeue_action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_exp_csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the number of rows to trim (8% of total rows)\n",
    "# rows_to_trim = int(len(df) * 0.02)\n",
    "\n",
    "# # Trim the top 5% of the DataFrame\n",
    "# trimmed_df = df.iloc[rows_to_trim:]\n",
    "\n",
    "# # Reset the index of the trimmed DataFrame\n",
    "# trimmed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Display the trimmed DataFrame\n",
    "# print(trimmed_df)\n",
    "# df = trimmed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen_Exp_Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536439"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Experience pool saved at: exp_pool_l4s_eval.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class ExperiencePool:\n",
    "    \"\"\"\n",
    "    Experience pool for collecting trajectories.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "    def add(self, state, action, reward, done):\n",
    "        self.states.append(state)  # sometimes state is also called obs (observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "\n",
    "# Define the list of columns to include\n",
    "columns_to_use = [\n",
    "    'queue_type', \n",
    "    'burst_allowance',\n",
    "    'drop_probability',\n",
    "    'current_queue_delay',\n",
    "    'accumulated_probability',\n",
    "    'average_dequeue_time',\n",
    "    'length_in_bytes',\n",
    "    'total_drops'\n",
    "]\n",
    "\n",
    "# Variable to store the window size (number of rows to collect)\n",
    "window_size = 5\n",
    "\n",
    "# Initialize the experience pool\n",
    "exp_pool = ExperiencePool()\n",
    "\n",
    "# Initialize variables for tracking previous action and accumulating rows\n",
    "prev_action = None\n",
    "row_buffer = []\n",
    "count=0\n",
    "\n",
    "# Iterate through each row and update the experience pool\n",
    "for index, row in df.iterrows():\n",
    "    state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "    current_action = row['dequeue_action']\n",
    "    \n",
    "    if prev_action is not None and current_action != prev_action:\n",
    "        count+=1\n",
    "        # If there's a change in action, collect the last 'window_size' rows\n",
    "        start_index = max(0, index - window_size)  # Ensure we don't go below 0\n",
    "        end_index = index  # Exclude the current row (where the action changed)\n",
    "\n",
    "        # Select the last 'window_size' rows and add them to the experience pool\n",
    "        selected_rows = df.iloc[start_index:end_index]\n",
    "        for _, selected_row in selected_rows.iterrows():\n",
    "            state = np.array(selected_row[columns_to_use], dtype=np.float32)\n",
    "            exp_pool.add(state=state, action=selected_row['dequeue_action'], reward=selected_row['current_queue_delay'], done=0)\n",
    "        \n",
    "        # Clear buffer as we only want the last 50 rows at each action change\n",
    "        row_buffer = []\n",
    "\n",
    "    # Add current row to the buffer (though it won't be used in the final experience pool)\n",
    "    row_buffer.append(row)\n",
    "    if index > df.shape[0] *0.06:\n",
    "        break;\n",
    "    \n",
    "    # Update the previous action\n",
    "    prev_action = current_action\n",
    "\n",
    "# Save the experience pool\n",
    "pickle_save_path = 'exp_pool_l4s_train.pkl'\n",
    "with open(pickle_save_path, 'wb') as f:\n",
    "    pickle.dump(exp_pool, f)\n",
    "\n",
    "print(f\"Done. Experience pool saved at: {pickle_save_path}\")\n",
    "import os\n",
    "# Delete the output file after processing\n",
    "os.remove('lmprocesseddata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272108"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_pool.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523.25"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10465/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def discount_returns(rewards, gamma, scale):\n",
    "    returns = [0 for _ in range(len(rewards))]\n",
    "    returns[-1] = rewards[-1]\n",
    "    for i in reversed(range(len(rewards) - 1)):\n",
    "        returns[i] = rewards[i] + gamma * returns[i + 1]\n",
    "    for i in range(len(returns)):\n",
    "        returns[i] /= scale  # scale down return\n",
    "    return returns\n",
    "\n",
    "\n",
    "class ExperienceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class that wraps the experience pool.\n",
    "    \"\"\"\n",
    "    def __init__(self, exp_pool, gamma=1., scale=10, max_length=30, sample_step=None) -> None:\n",
    "        \"\"\"\n",
    "        :param exp_pool: the experience pool\n",
    "        :param gamma: the reward discounted factor\n",
    "        :param scale: the factor to scale the return\n",
    "        :param max_length: the w value in our paper, see the paper for details.\n",
    "        \"\"\"\n",
    "        if sample_step is None:\n",
    "            sample_step = max_length\n",
    "\n",
    "        self.exp_pool = exp_pool\n",
    "        self.exp_pool_size = len(exp_pool)\n",
    "        self.gamma = gamma\n",
    "        self.scale = scale\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.returns = []\n",
    "        self.timesteps = []\n",
    "        self.rewards = []\n",
    "\n",
    "        self.exp_dataset_info = {}\n",
    "\n",
    "        self._normalize_rewards()\n",
    "        self._compute_returns()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_action': max(self.actions),\n",
    "            'min_action': min(self.actions)\n",
    "        })\n",
    "\n",
    "        self.dataset_indices = list(range(0, self.exp_pool_size - max_length + 1, min(sample_step, max_length)))\n",
    "    \n",
    "    def sample_batch(self, batch_size=1, batch_indices=None):\n",
    "        \"\"\"\n",
    "        Sample a batch of data from the experience pool.\n",
    "        :param batch_size: the size of a batch. For CJS task, batch_size should be set to 1 due to the unstructural data format.\n",
    "        \"\"\"\n",
    "        if batch_indices is None:\n",
    "            batch_indices = np.random.choice(len(self.dataset_indices), size=batch_size)\n",
    "        batch_states, batch_actions, batch_returns, batch_timesteps = [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            states, actions, returns, timesteps = self[batch_indices[i]]\n",
    "            batch_states.append(states)\n",
    "            batch_actions.append(actions)\n",
    "            batch_returns.append(returns)\n",
    "            batch_timesteps.append(timesteps)\n",
    "        return batch_states, batch_actions, batch_returns, batch_timesteps\n",
    "    \n",
    "    @property\n",
    "    def states(self):\n",
    "        return self.exp_pool.states\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self.exp_pool.actions\n",
    "    \n",
    "    @property\n",
    "    def dones(self):\n",
    "        return self.exp_pool.dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start = self.dataset_indices[index]\n",
    "        end = start + self.max_length\n",
    "        return self.states[start:end], self.actions[start:end], self.returns[start:end], self.timesteps[start:end]\n",
    "\n",
    "    def _normalize_rewards(self):\n",
    "        min_reward, max_reward = min(self.exp_pool.rewards), max(self.exp_pool.rewards)\n",
    "        rewards = (np.array(self.exp_pool.rewards) - min_reward) / (max_reward - min_reward)\n",
    "        self.rewards = rewards.tolist()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_reward': max_reward,\n",
    "            'min_reward': min_reward,\n",
    "        })\n",
    "\n",
    "    def _compute_returns(self):\n",
    "        \"\"\"\n",
    "        Compute returns (discounted cumulative rewards)\n",
    "        \"\"\"\n",
    "        episode_start = 0\n",
    "        while episode_start < self.exp_pool_size:\n",
    "            try:\n",
    "                episode_end = self.dones.index(True, episode_start) + 1\n",
    "            except ValueError:\n",
    "                episode_end = self.exp_pool_size\n",
    "            self.returns.extend(discount_returns(self.rewards[episode_start:episode_end], self.gamma, self.scale))\n",
    "            self.timesteps += list(range(episode_end - episode_start))\n",
    "            episode_start = episode_end\n",
    "        assert len(self.returns) == len(self.timesteps)\n",
    "        self.exp_dataset_info.update({\n",
    "            # for normalizing rewards/returns\n",
    "            'max_return': max(self.returns),\n",
    "            'min_return': min(self.returns),\n",
    "\n",
    "            # to help determine the maximum size of timesteps embedding\n",
    "            'min_timestep': min(self.timesteps),\n",
    "            'max_timestep': max(self.timesteps),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first element in states: <class 'torch.Tensor'>\n",
      "process_batch states type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "exp_dataset = ExperienceDataset(exp_pool, gamma=1.0, scale=1000, max_length=20, sample_step=10)\n",
    "batch_size =1\n",
    "exp_dataset_info = Munch(exp_dataset.exp_dataset_info)\n",
    "dataloader = DataLoader(exp_dataset, batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "    states, actions, returns, timesteps = batch\n",
    "    print(\"Type of first element in states:\", type(states[0]))\n",
    "    print(\"process_batch states type:\",type(states))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27209\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for step, batch in enumerate(dataloader):\n",
    "    count+=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vizenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
