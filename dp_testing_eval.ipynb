{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the input file and output file in the same context\n",
    "# with open('llmrawdata.txt', 'r') as infile, open('lmprocesseddata.txt', 'w') as outfile:\n",
    "#     for line in infile:\n",
    "#         if 'l4s_ecn_marking-start' in line:\n",
    "#             # Remove the prefix 'l4s_ecn_marking-start,' and trailing ' end'\n",
    "#             temp=line.split(\"-\")\n",
    "#             temp1=temp[1]\n",
    "            \n",
    "#             temp1=temp1.split(\",\")\n",
    "#             #print(temp1[-1]==\"end \\n\")\n",
    "#             if(temp1[-1]==\"end \\n\"):\n",
    "#                 outfile.writelines(temp[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input file and output file in the same context\n",
    "with open('llmrawdata.txt', 'r') as infile, open('lmprocesseddata.txt', 'w') as outfile:\n",
    "    for line in infile:\n",
    "        if 'l4s_ecn_marking-start' in line:\n",
    "            # Remove the prefix 'l4s_ecn_marking-start,' and trailing ' end'\n",
    "            parts = line.split(\"-\")\n",
    "            if len(parts) > 1:\n",
    "                content = parts[1].strip()  # Remove any leading/trailing whitespace\n",
    "                if content.endswith('end'):\n",
    "                    # Write the content to the output file, stripping the 'end' part\n",
    "                    outfile.write(content[6:-4] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\n",
    "    \"queue_type\",                   # q->queue_type\n",
    "    \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "    \"tupdate\",                      # pprms->tupdate\n",
    "    \"max_burst\",                    # pprms->max_burst\n",
    "    \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "    \"alpha_coefficient\",            # pprms->alpha\n",
    "    \"beta_coefficient\",             # pprms->beta\n",
    "    \"flags\",                        # pprms->flags\n",
    "    \"burst_allowance\",              # pst->burst_allowance\n",
    "    \"drop_probability\",             # pst->drop_prob\n",
    "    \"current_queue_delay\",          # pst->current_qdelay\n",
    "    \"previous_queue_delay\",         # pst->qdelay_old\n",
    "    \"accumulated_probability\",      # pst->accu_prob\n",
    "    \"measurement_start_time\",       # pst->measurement_start\n",
    "    \"average_dequeue_time\",         # pst->avg_dq_time\n",
    "    \"dequeue_count\",                # pst->dq_count\n",
    "    \"status_flags\",                 # pst->sflags\n",
    "    \"total_packets\",                # q->stats.tot_pkts\n",
    "    \"total_bytes\",                  # q->stats.tot_bytes\n",
    "    \"queue_length\",                 # q->stats.length\n",
    "    \"length_in_bytes\",              # q->stats.len_bytes\n",
    "    \"total_drops\",                  # q->stats.drops\n",
    "    \"dequeue_action\",               # dequeue_action\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"lmprocesseddata.txt\",names=column_list,header=None)\n",
    "\n",
    "# Drop columns that contain 'pprms' in their name\n",
    "columns_to_drop = [\n",
    "    \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "    \"tupdate\",                      # pprms->tupdate\n",
    "    \"max_burst\",                    # pprms->max_burst\n",
    "    \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "    \"alpha_coefficient\",            # pprms->alpha\n",
    "    \"beta_coefficient\",             # pprms->beta\n",
    "    \"flags\",                        # pprms->flags\n",
    "    ]\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"verify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536448 entries, 0 to 536447\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count   Dtype\n",
      "---  ------                   --------------   -----\n",
      " 0   queue_type               536448 non-null  int64\n",
      " 1   burst_allowance          536448 non-null  int64\n",
      " 2   drop_probability         536448 non-null  int64\n",
      " 3   current_queue_delay      536448 non-null  int64\n",
      " 4   previous_queue_delay     536448 non-null  int64\n",
      " 5   accumulated_probability  536448 non-null  int64\n",
      " 6   measurement_start_time   536448 non-null  int64\n",
      " 7   average_dequeue_time     536448 non-null  int64\n",
      " 8   dequeue_count            536448 non-null  int64\n",
      " 9   status_flags             536448 non-null  int64\n",
      " 10  total_packets            536448 non-null  int64\n",
      " 11  total_bytes              536448 non-null  int64\n",
      " 12  queue_length             536448 non-null  int64\n",
      " 13  length_in_bytes          536448 non-null  int64\n",
      " 14  total_drops              536448 non-null  int64\n",
      " 15  dequeue_action           536448 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 65.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dequeue_action']=df['dequeue_action']-1\n",
    "df['dequeue_action'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dequeue_action\n",
       "0    532366\n",
       "1      3394\n",
       "2       688\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dequeue_action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queue_type',\n",
       " 'burst_allowance',\n",
       " 'drop_probability',\n",
       " 'current_queue_delay',\n",
       " 'previous_queue_delay',\n",
       " 'accumulated_probability',\n",
       " 'measurement_start_time',\n",
       " 'average_dequeue_time',\n",
       " 'dequeue_count',\n",
       " 'status_flags',\n",
       " 'total_packets',\n",
       " 'total_bytes',\n",
       " 'queue_length',\n",
       " 'length_in_bytes',\n",
       " 'total_drops',\n",
       " 'dequeue_action']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107289.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] *0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "         queue_type  burst_allowance  drop_probability  current_queue_delay  \\\n",
      "376108           0                0                 0                50000   \n",
      "381997           0           105000            539360                50000   \n",
      "260248           0           135000             12451                10000   \n",
      "125131           0                0             20316                50000   \n",
      "285600           1                0             29490                30000   \n",
      "...            ...              ...               ...                  ...   \n",
      "110268           0            60000          20799158               110000   \n",
      "259178           0            30000          14459204               120000   \n",
      "365838           0            45000           8284404                90000   \n",
      "131932           0                0         106335427                70000   \n",
      "121958           1                0                 0                20000   \n",
      "\n",
      "        previous_queue_delay  accumulated_probability  measurement_start_time  \\\n",
      "376108                 50000                        0               392152704   \n",
      "381997                 40000                  3838423               398932704   \n",
      "260248                 10000                   199216               207212704   \n",
      "125131                 70000                   548532              4280220000   \n",
      "285600                 40000                   635673               231482704   \n",
      "...                      ...                      ...                     ...   \n",
      "110268                110000                302297141              4221200000   \n",
      "259178                 90000                357929942               205982704   \n",
      "365838                 90000                 54453172               382862704   \n",
      "131932                 70000              11363997526              4286580000   \n",
      "121958                 20000                        0              4231980000   \n",
      "\n",
      "        average_dequeue_time  dequeue_count  status_flags  total_packets  \\\n",
      "376108                     0              0             3          14945   \n",
      "381997                     0              0             3          18701   \n",
      "260248                     0              0             3           9250   \n",
      "125131                     0              0             3           1116   \n",
      "285600                     0              0             3          11589   \n",
      "...                      ...            ...           ...            ...   \n",
      "110268                     0              0             3          30746   \n",
      "259178                     0              0             3           8554   \n",
      "365838                     0              0             3           8082   \n",
      "131932                     0              0             3           6213   \n",
      "121958                     0              0             3          20982   \n",
      "\n",
      "        total_bytes  queue_length  length_in_bytes  total_drops  \n",
      "376108     10653508            61            61092           92  \n",
      "381997     13065812             9            10604          182  \n",
      "260248      7297520            41            41228           25  \n",
      "125131       936542            31            37812            0  \n",
      "285600     17379230            11            16500            0  \n",
      "...             ...           ...              ...          ...  \n",
      "110268     21338882            84           121716          250  \n",
      "259178      6816792            46            48728           24  \n",
      "365838      5629024            55            30784           15  \n",
      "131932      5144482            51            59124            7  \n",
      "121958     31461824            27            40500            8  \n",
      "\n",
      "[429158 rows x 15 columns]\n",
      "Testing Features:\n",
      "         queue_type  burst_allowance  drop_probability  current_queue_delay  \\\n",
      "300290           0           135000             12451                50000   \n",
      "122010           0                0                 0                70000   \n",
      "195375           0                0         617330086               110000   \n",
      "320911           0                0         160342334                90000   \n",
      "302136           0           150000                 0                    0   \n",
      "...            ...              ...               ...                  ...   \n",
      "421333           0            30000          82666451               140000   \n",
      "400616           0           150000                 0                    0   \n",
      "262381           1           150000                 0                    0   \n",
      "63171            0                0                 0                30000   \n",
      "196993           0            90000           1074133                60000   \n",
      "\n",
      "        previous_queue_delay  accumulated_probability  measurement_start_time  \\\n",
      "300290                 10000                   161863               246042704   \n",
      "122010                 60000                        0              4231980000   \n",
      "195375                100000              17885052747                95712704   \n",
      "320911                 90000              11301485583               310642704   \n",
      "302136                     0                        0               247932704   \n",
      "...                      ...                      ...                     ...   \n",
      "421333                140000               2782272955               481192704   \n",
      "400616                     0                        0               417122704   \n",
      "262381                     0                        0               209362704   \n",
      "63171                  30000                        0              4174190000   \n",
      "196993                 60000                  3725700               100872704   \n",
      "\n",
      "        average_dequeue_time  dequeue_count  status_flags  total_packets  \\\n",
      "300290                     0              0             0          35690   \n",
      "122010                     0              0             3          38466   \n",
      "195375                     0              0             3           6621   \n",
      "320911                     0              0             3          10798   \n",
      "302136                     0              0             3          36711   \n",
      "...                      ...            ...           ...            ...   \n",
      "421333                     0              0             3           7481   \n",
      "400616                     0              0             3          34115   \n",
      "262381                     0              0             3           4327   \n",
      "63171                      0              0             3            426   \n",
      "196993                     0              0             3           7624   \n",
      "\n",
      "        total_bytes  queue_length  length_in_bytes  total_drops  \n",
      "300290     25611668             0                0          451  \n",
      "122010     26715968            46            28456          280  \n",
      "195375      4591204            49            14268           39  \n",
      "320911     10950932           115           156572            2  \n",
      "302136     26171292             8             1900          451  \n",
      "...             ...           ...              ...          ...  \n",
      "421333      6132236            83            57892           25  \n",
      "400616     26038662            25            23020          338  \n",
      "262381      6487678             2             3000            0  \n",
      "63171        304234            26            17280            0  \n",
      "196993      5137772            26            21660           73  \n",
      "\n",
      "[107290 rows x 15 columns]\n",
      "Training Target:\n",
      " 376108    0\n",
      "381997    0\n",
      "260248    0\n",
      "125131    0\n",
      "285600    0\n",
      "         ..\n",
      "110268    0\n",
      "259178    0\n",
      "365838    0\n",
      "131932    0\n",
      "121958    0\n",
      "Name: dequeue_action, Length: 429158, dtype: int64\n",
      "Testing Target:\n",
      " 300290    0\n",
      "122010    0\n",
      "195375    0\n",
      "320911    0\n",
      "302136    0\n",
      "         ..\n",
      "421333    0\n",
      "400616    0\n",
      "262381    0\n",
      "63171     0\n",
      "196993    0\n",
      "Name: dequeue_action, Length: 107290, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splitting the DataFrame into features and target\n",
    "X = df.drop('dequeue_action', axis=1)  # Features\n",
    "y = df['dequeue_action']                # Target variable\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Output the results\n",
    "print(\"Training Features:\\n\", X_train)\n",
    "print(\"Testing Features:\\n\", X_test)\n",
    "print(\"Training Target:\\n\", y_train)\n",
    "print(\"Testing Target:\\n\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queue_type</th>\n",
       "      <th>burst_allowance</th>\n",
       "      <th>drop_probability</th>\n",
       "      <th>current_queue_delay</th>\n",
       "      <th>previous_queue_delay</th>\n",
       "      <th>accumulated_probability</th>\n",
       "      <th>measurement_start_time</th>\n",
       "      <th>average_dequeue_time</th>\n",
       "      <th>dequeue_count</th>\n",
       "      <th>status_flags</th>\n",
       "      <th>total_packets</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>queue_length</th>\n",
       "      <th>length_in_bytes</th>\n",
       "      <th>total_drops</th>\n",
       "      <th>dequeue_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048030000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>16556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048050000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>16668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048060000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>16884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048070000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>16924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4048070000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>16964</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536443</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971502704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>7240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536444</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971522704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>7280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536445</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971542704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>7364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536446</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971562704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>7404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536447</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>971562704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>7588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536448 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        queue_type  burst_allowance  drop_probability  current_queue_delay  \\\n",
       "0                0           150000                 0                10000   \n",
       "1                0           150000                 0                    0   \n",
       "2                0           150000                 0                    0   \n",
       "3                0           150000                 0                    0   \n",
       "4                0           150000                 0                    0   \n",
       "...            ...              ...               ...                  ...   \n",
       "536443           0           150000                 0                    0   \n",
       "536444           0           150000                 0                    0   \n",
       "536445           0           150000                 0                    0   \n",
       "536446           0           150000                 0                    0   \n",
       "536447           0           150000                 0                10000   \n",
       "\n",
       "        previous_queue_delay  accumulated_probability  measurement_start_time  \\\n",
       "0                          0                        0              4048030000   \n",
       "1                          0                        0              4048050000   \n",
       "2                          0                        0              4048060000   \n",
       "3                          0                        0              4048070000   \n",
       "4                          0                        0              4048070000   \n",
       "...                      ...                      ...                     ...   \n",
       "536443                     0                        0               971502704   \n",
       "536444                     0                        0               971522704   \n",
       "536445                     0                        0               971542704   \n",
       "536446                     0                        0               971562704   \n",
       "536447                     0                        0               971562704   \n",
       "\n",
       "        average_dequeue_time  dequeue_count  status_flags  total_packets  \\\n",
       "0                          0              0             0             87   \n",
       "1                          0              0             0             88   \n",
       "2                          0              0             0             89   \n",
       "3                          0              0             3             90   \n",
       "4                          0              0             3             91   \n",
       "...                      ...            ...           ...            ...   \n",
       "536443                     0              0             0             31   \n",
       "536444                     0              0             0             32   \n",
       "536445                     0              0             0             33   \n",
       "536446                     0              0             3             34   \n",
       "536447                     0              0             0             35   \n",
       "\n",
       "        total_bytes  queue_length  length_in_bytes  total_drops  \\\n",
       "0             16556             0                0            0   \n",
       "1             16668             0                0            0   \n",
       "2             16884             0                0            0   \n",
       "3             16924             0                0            0   \n",
       "4             16964             1               40            0   \n",
       "...             ...           ...              ...          ...   \n",
       "536443         7240             0                0            0   \n",
       "536444         7280             0                0            0   \n",
       "536445         7364             0                0            0   \n",
       "536446         7404             0                0            0   \n",
       "536447         7588             0                0            0   \n",
       "\n",
       "        dequeue_action  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "536443               0  \n",
       "536444               0  \n",
       "536445               0  \n",
       "536446               0  \n",
       "536447               0  \n",
       "\n",
       "[536448 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ExperiencePool:\n",
    "#     \"\"\"\n",
    "#     Experience pool for collecting trajectories.\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.states = []\n",
    "#         self.actions = []\n",
    "#         self.rewards = []\n",
    "#         self.dones = []\n",
    "\n",
    "#     def add(self, state, action, reward, done):\n",
    "#         self.states.append(state)  # sometime state is also called obs (observation)\n",
    "#         self.actions.append(action)\n",
    "#         self.rewards.append(reward)\n",
    "#         self.dones.append(done)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.states)\n",
    "\n",
    "# # Define the list of columns to include\n",
    "# columns_to_use = [\n",
    "#     'queue_type', \n",
    "#     'burst_allowance',\n",
    "#     'drop_probability',\n",
    "#     'current_queue_delay',\n",
    "#     'accumulated_probability',\n",
    "#     'average_dequeue_time',\n",
    "#     'total_bytes',\n",
    "#     'total_drops'\n",
    "# ]\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# exp_pool = ExperiencePool()\n",
    "# # Initialize the global reward variable\n",
    "# global_reward = 0\n",
    "\n",
    "# # Iterate through each row and update the global reward variable\n",
    "# for index, row in df.iterrows():\n",
    "#     # print(row[columns_to_use])\n",
    "#     state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "#     print(type(state))\n",
    "#     exp_pool.add(state=state, action=row['dequeue_action'], reward=row['current_queue_delay'], done=0)\n",
    "#     break;\n",
    "\n",
    "# pickle_save_path='exp_pool_l4s.pkl'\n",
    "# pickle.dump(exp_pool, open( pickle_save_path, 'wb'))\n",
    "# print(f\"Done. Experience pool saved at:\", pickle_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ExperiencePool:\n",
    "#     \"\"\"\n",
    "#     Experience pool for collecting trajectories.\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.states = []\n",
    "#         self.actions = []\n",
    "#         self.rewards = []\n",
    "#         self.dones = []\n",
    "\n",
    "#     def add(self, state, action, reward, done):\n",
    "#         self.states.append(state)  # sometime state is also called obs (observation)\n",
    "#         self.actions.append(action)\n",
    "#         self.rewards.append(reward)\n",
    "#         self.dones.append(done)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.states)\n",
    "\n",
    "# # Define the list of columns to include\n",
    "# columns_to_use = [\n",
    "#     'queue_type', \n",
    "#     'burst_allowance',\n",
    "#     'drop_probability',\n",
    "#     'current_queue_delay',\n",
    "#     'accumulated_probability',\n",
    "#     'average_dequeue_time',\n",
    "#     'total_bytes',\n",
    "#     'total_drops'\n",
    "# ]\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# exp_pool = ExperiencePool()\n",
    "# # Initialize the global reward variable\n",
    "# global_reward = 0\n",
    "\n",
    "# # Iterate through each row and update the global reward variable\n",
    "# for index, row in df.iterrows():\n",
    "#     state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "#     exp_pool.add(state=state, action=row['dequeue_action'], reward=row['current_queue_delay'], done=0)\n",
    "#     if index > df.shape[0] *0.005:\n",
    "#         break;\n",
    "\n",
    "# pickle_save_path='exp_pool_l4s.pkl'\n",
    "# pickle.dump(exp_pool, open( pickle_save_path, 'wb'))\n",
    "# print(f\"Done. Experience pool saved at:\", pickle_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        queue_type  burst_allowance  drop_probability  current_queue_delay  \\\n",
      "0                0            60000          11103761               140000   \n",
      "1                1            45000          20205403               100000   \n",
      "2                1            45000          20205403               100000   \n",
      "3                0            45000          28719837               140000   \n",
      "4                1            45000          20205403               100000   \n",
      "...            ...              ...               ...                  ...   \n",
      "348687           0           150000                 0                    0   \n",
      "348688           0           150000                 0                    0   \n",
      "348689           0           150000                 0                    0   \n",
      "348690           0           150000                 0                    0   \n",
      "348691           0           150000                 0                10000   \n",
      "\n",
      "        previous_queue_delay  accumulated_probability  measurement_start_time  \\\n",
      "0                     100000                184340857                91762704   \n",
      "1                     100000                594399630                91762704   \n",
      "2                     100000                614605033                91762704   \n",
      "3                     140000                213060694                91762704   \n",
      "4                     100000                634810436                91762704   \n",
      "...                      ...                      ...                     ...   \n",
      "348687                     0                        0               971502704   \n",
      "348688                     0                        0               971522704   \n",
      "348689                     0                        0               971542704   \n",
      "348690                     0                        0               971562704   \n",
      "348691                     0                        0               971562704   \n",
      "\n",
      "        average_dequeue_time  dequeue_count  status_flags  total_packets  \\\n",
      "0                          0              0             3           1857   \n",
      "1                          0              0             3            886   \n",
      "2                          0              0             3            887   \n",
      "3                          0              0             3           1858   \n",
      "4                          0              0             3            888   \n",
      "...                      ...            ...           ...            ...   \n",
      "348687                     0              0             0             31   \n",
      "348688                     0              0             0             32   \n",
      "348689                     0              0             0             33   \n",
      "348690                     0              0             3             34   \n",
      "348691                     0              0             0             35   \n",
      "\n",
      "        total_bytes  queue_length  length_in_bytes  total_drops  \\\n",
      "0           1423248            53            70812            2   \n",
      "1           1311684            56            84000            0   \n",
      "2           1313184            57            85500            0   \n",
      "3           1424748            54            72312            2   \n",
      "4           1314684            58            87000            0   \n",
      "...             ...           ...              ...          ...   \n",
      "348687         7240             0                0            0   \n",
      "348688         7280             0                0            0   \n",
      "348689         7364             0                0            0   \n",
      "348690         7404             0                0            0   \n",
      "348691         7588             0                0            0   \n",
      "\n",
      "        dequeue_action  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    0  \n",
      "...                ...  \n",
      "348687               0  \n",
      "348688               0  \n",
      "348689               0  \n",
      "348690               0  \n",
      "348691               0  \n",
      "\n",
      "[348692 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows to trim (5% of total rows)\n",
    "rows_to_trim = int(len(df) * 0.35)\n",
    "\n",
    "# Trim the top 5% of the DataFrame\n",
    "trimmed_df = df.iloc[rows_to_trim:]\n",
    "\n",
    "# Reset the index of the trimmed DataFrame\n",
    "trimmed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the trimmed DataFrame\n",
    "print(trimmed_df)\n",
    "df = trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348692, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Experience pool saved at: exp_pool_l4s_test.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class ExperiencePool:\n",
    "    \"\"\"\n",
    "    Experience pool for collecting trajectories.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "    def add(self, state, action, reward, done):\n",
    "        self.states.append(state)  # sometimes state is also called obs (observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "\n",
    "# Define the list of columns to include\n",
    "columns_to_use = [\n",
    "    'queue_type', \n",
    "    'burst_allowance',\n",
    "    'drop_probability',\n",
    "    'current_queue_delay',\n",
    "    'accumulated_probability',\n",
    "    'average_dequeue_time',\n",
    "    'length_in_bytes',\n",
    "    'total_drops'\n",
    "]\n",
    "\n",
    "# Variable to store the window size (number of rows to collect)\n",
    "window_size = 5\n",
    "\n",
    "# Initialize the experience pool\n",
    "exp_pool = ExperiencePool()\n",
    "\n",
    "# Initialize variables for tracking previous action and accumulating rows\n",
    "prev_action = None\n",
    "row_buffer = []\n",
    "count=0\n",
    "\n",
    "# Iterate through each row and update the experience pool\n",
    "for index, row in df.iterrows():\n",
    "    state = np.array(row[columns_to_use], dtype=np.float32)\n",
    "    current_action = row['dequeue_action']\n",
    "    if prev_action is not None and current_action != prev_action:\n",
    "        count+=1\n",
    "        # If there's a change in action, collect the last 'window_size' rows\n",
    "        start_index = max(0, index - window_size)  # Ensure we don't go below 0\n",
    "        end_index = index  # Exclude the current row (where the action changed)\n",
    "\n",
    "        # Select the last 'window_size' rows and add them to the experience pool\n",
    "        selected_rows = df.iloc[start_index:end_index]\n",
    "        for _, selected_row in selected_rows.iterrows():\n",
    "            state = np.array(selected_row[columns_to_use], dtype=np.float32)\n",
    "            exp_pool.add(state=state, action=selected_row['dequeue_action'], reward=selected_row['current_queue_delay'], done=0)\n",
    "        \n",
    "        # Clear buffer as we only want the last 50 rows at each action change\n",
    "        row_buffer = []\n",
    "\n",
    "    # Add current row to the buffer (though it won't be used in the final experience pool)\n",
    "    row_buffer.append(row)\n",
    "    if index > df.shape[0] *0.05:\n",
    "        break;\n",
    "    \n",
    "    # Update the previous action\n",
    "    prev_action = current_action\n",
    "\n",
    "# Save the experience pool\n",
    "pickle_save_path = 'exp_pool_l4s_test.pkl'\n",
    "with open(pickle_save_path, 'wb') as f:\n",
    "    pickle.dump(exp_pool, f)\n",
    "\n",
    "print(f\"Done. Experience pool saved at: {pickle_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_pool.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def discount_returns(rewards, gamma, scale):\n",
    "    returns = [0 for _ in range(len(rewards))]\n",
    "    returns[-1] = rewards[-1]\n",
    "    for i in reversed(range(len(rewards) - 1)):\n",
    "        returns[i] = rewards[i] + gamma * returns[i + 1]\n",
    "    for i in range(len(returns)):\n",
    "        returns[i] /= scale  # scale down return\n",
    "    return returns\n",
    "\n",
    "\n",
    "class ExperienceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class that wraps the experience pool.\n",
    "    \"\"\"\n",
    "    def __init__(self, exp_pool, gamma=1., scale=10, max_length=30, sample_step=None) -> None:\n",
    "        \"\"\"\n",
    "        :param exp_pool: the experience pool\n",
    "        :param gamma: the reward discounted factor\n",
    "        :param scale: the factor to scale the return\n",
    "        :param max_length: the w value in our paper, see the paper for details.\n",
    "        \"\"\"\n",
    "        if sample_step is None:\n",
    "            sample_step = max_length\n",
    "\n",
    "        self.exp_pool = exp_pool\n",
    "        self.exp_pool_size = len(exp_pool)\n",
    "        self.gamma = gamma\n",
    "        self.scale = scale\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.returns = []\n",
    "        self.timesteps = []\n",
    "        self.rewards = []\n",
    "\n",
    "        self.exp_dataset_info = {}\n",
    "\n",
    "        self._normalize_rewards()\n",
    "        self._compute_returns()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_action': max(self.actions),\n",
    "            'min_action': min(self.actions)\n",
    "        })\n",
    "\n",
    "        self.dataset_indices = list(range(0, self.exp_pool_size - max_length + 1, min(sample_step, max_length)))\n",
    "    \n",
    "    def sample_batch(self, batch_size=1, batch_indices=None):\n",
    "        \"\"\"\n",
    "        Sample a batch of data from the experience pool.\n",
    "        :param batch_size: the size of a batch. For CJS task, batch_size should be set to 1 due to the unstructural data format.\n",
    "        \"\"\"\n",
    "        if batch_indices is None:\n",
    "            batch_indices = np.random.choice(len(self.dataset_indices), size=batch_size)\n",
    "        batch_states, batch_actions, batch_returns, batch_timesteps = [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            states, actions, returns, timesteps = self[batch_indices[i]]\n",
    "            batch_states.append(states)\n",
    "            batch_actions.append(actions)\n",
    "            batch_returns.append(returns)\n",
    "            batch_timesteps.append(timesteps)\n",
    "        return batch_states, batch_actions, batch_returns, batch_timesteps\n",
    "    \n",
    "    @property\n",
    "    def states(self):\n",
    "        return self.exp_pool.states\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self.exp_pool.actions\n",
    "    \n",
    "    @property\n",
    "    def dones(self):\n",
    "        return self.exp_pool.dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start = self.dataset_indices[index]\n",
    "        end = start + self.max_length\n",
    "        return self.states[start:end], self.actions[start:end], self.returns[start:end], self.timesteps[start:end]\n",
    "\n",
    "    def _normalize_rewards(self):\n",
    "        min_reward, max_reward = min(self.exp_pool.rewards), max(self.exp_pool.rewards)\n",
    "        rewards = (np.array(self.exp_pool.rewards) - min_reward) / (max_reward - min_reward)\n",
    "        self.rewards = rewards.tolist()\n",
    "        self.exp_dataset_info.update({\n",
    "            'max_reward': max_reward,\n",
    "            'min_reward': min_reward,\n",
    "        })\n",
    "\n",
    "    def _compute_returns(self):\n",
    "        \"\"\"\n",
    "        Compute returns (discounted cumulative rewards)\n",
    "        \"\"\"\n",
    "        episode_start = 0\n",
    "        while episode_start < self.exp_pool_size:\n",
    "            try:\n",
    "                episode_end = self.dones.index(True, episode_start) + 1\n",
    "            except ValueError:\n",
    "                episode_end = self.exp_pool_size\n",
    "            self.returns.extend(discount_returns(self.rewards[episode_start:episode_end], self.gamma, self.scale))\n",
    "            self.timesteps += list(range(episode_end - episode_start))\n",
    "            episode_start = episode_end\n",
    "        assert len(self.returns) == len(self.timesteps)\n",
    "        self.exp_dataset_info.update({\n",
    "            # for normalizing rewards/returns\n",
    "            'max_return': max(self.returns),\n",
    "            'min_return': min(self.returns),\n",
    "\n",
    "            # to help determine the maximum size of timesteps embedding\n",
    "            'min_timestep': min(self.timesteps),\n",
    "            'max_timestep': max(self.timesteps),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_save_path='artifacts/exp_pools/exp_pool_l4s_test.pkl'\n",
    "pickle_save_path='./exp_pool_l4s_test.pkl'\n",
    "# pickle_save_path='artifacts/exp_pools/exp_pool.pkl'\n",
    "exp_pool=pickle.load(open( pickle_save_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"lmprocesseddata.txt\",names=column_list,header=None)\n",
    "\n",
    "# Drop columns that contain 'pprms' in their name\n",
    "columns_to_drop = [\n",
    "    \"qdelay_reference\",             # pprms->qdelay_ref\n",
    "    \"tupdate\",                      # pprms->tupdate\n",
    "    \"max_burst\",                    # pprms->max_burst\n",
    "    \"max_ecn_threshold\",            # pprms->max_ecnth\n",
    "    \"alpha_coefficient\",            # pprms->alpha\n",
    "    \"beta_coefficient\",             # pprms->beta\n",
    "    \"flags\",                        # pprms->flags\n",
    "    ]\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qt_1=df[df['queue_type']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queue_type',\n",
       " 'burst_allowance',\n",
       " 'drop_probability',\n",
       " 'current_queue_delay',\n",
       " 'accumulated_probability',\n",
       " 'average_dequeue_time',\n",
       " 'length_in_bytes',\n",
       " 'total_drops']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Randomly select from the list [0, 1, 2]\n",
    "random_value = random.choice([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_length(df, user_input):\n",
    "    if df.empty:\n",
    "        # Handle the empty DataFrame case\n",
    "        print(\"DataFrame is empty, returning None.\")\n",
    "        return None  # Return None or another suitable default value\n",
    "\n",
    "    # Calculate the absolute difference with user input\n",
    "    nearest_idx = (df['length_in_bytes'] - user_input).abs().idxmin()\n",
    "    \n",
    "    if nearest_idx is None or nearest_idx >= len(df):\n",
    "        print(\"No valid index found, returning None.\")\n",
    "        return None  # Return None or another suitable default value\n",
    "\n",
    "    return df.iloc[nearest_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "queue_type                          0\n",
       "burst_allowance                150000\n",
       "drop_probability                    0\n",
       "current_queue_delay             10000\n",
       "previous_queue_delay                0\n",
       "accumulated_probability             0\n",
       "measurement_start_time     4048030000\n",
       "average_dequeue_time                0\n",
       "dequeue_count                       0\n",
       "status_flags                        0\n",
       "total_packets                      87\n",
       "total_bytes                     16556\n",
       "queue_length                        0\n",
       "length_in_bytes                     0\n",
       "total_drops                         0\n",
       "dequeue_action                      1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "States:\n",
      "tensor([[0.0000e+00, 1.3500e+05, 1.2451e+04, 1.0000e+04, 1.9922e+05, 0.0000e+00,\n",
      "         2.0648e+04, 7.3000e+01]])\n",
      "torch.Size([1, 8])\n",
      "Actions:\n",
      "tensor([0])\n",
      "torch.Size([1])\n",
      "Returns:\n",
      "tensor([0.1693], dtype=torch.float64)\n",
      "torch.Size([1])\n",
      "Timesteps:\n",
      "tensor([916])\n",
      "torch.Size([1])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming exp_dataset and other components are already defined and initialized\n",
    "exp_dataset = ExperienceDataset(exp_pool, gamma=1.0, scale=1000, max_length=1, sample_step=10)\n",
    "\n",
    "batch_size = 1\n",
    "exp_dataset_info = Munch(exp_dataset.exp_dataset_info)\n",
    "dataloader = DataLoader(exp_dataset, batch_size, shuffle=True, pin_memory=True)\n",
    "results_df = pd.DataFrame(columns=columns_to_use)\n",
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "    states, actions, returns, timesteps = batch\n",
    "\n",
    "    # Print states, actions, returns, timesteps and their types and shapes\n",
    "    print(f\"Step {step + 1}:\")\n",
    "    print(\"States:\")\n",
    "    print(states[0])\n",
    "    print(states[0].shape)\n",
    "    \n",
    "    print(\"Actions:\")\n",
    "    print(actions[0])\n",
    "    print(actions[0].shape)\n",
    "    \n",
    "    print(\"Returns:\")\n",
    "    print(returns[0])\n",
    "    print(returns[0].shape)\n",
    "    \n",
    "    print(\"Timesteps:\")\n",
    "    print(timesteps[0])\n",
    "    print(timesteps[0].shape)\n",
    "\n",
    "    # Optional: Add a separator for readability\n",
    "    print(\"-\" * 40)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ats.shape (372340, 16)\n",
      "states[0][0][6] tensor(53952.)\n",
      "DataPoint\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index(['queue_type', 'burst_allowance', 'drop_probability',\n",
      "       'current_queue_delay', 'previous_queue_delay',\n",
      "       'accumulated_probability', 'measurement_start_time',\n",
      "       'average_dequeue_time', 'dequeue_count', 'status_flags',\n",
      "       'total_packets', 'total_bytes', 'queue_length', 'length_in_bytes',\n",
      "       'total_drops', 'dequeue_action'],\n",
      "      dtype='object')\n",
      " (372340, 16)\n",
      " tensor(53952.)\n",
      " 1\n",
      " 0\n",
      " torch.Size([1, 8])\n",
      " torch.Size([8])\n",
      " torch.Size([])\n",
      " [tensor(0.), tensor(0.), tensor(5.7706e+08), tensor(160000.), tensor(1.8424e+10), tensor(0.), tensor(53952.), tensor(24.)]\n",
      "Type of first element in states: <class 'torch.Tensor'>\n",
      "process_batch states type: <class 'list'>\n",
      "Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "exp_dataset = ExperienceDataset(exp_pool, gamma=1.0, scale=1000, max_length=1, sample_step=10)\n",
    "batch_size =1\n",
    "exp_dataset_info = Munch(exp_dataset.exp_dataset_info)\n",
    "dataloader = DataLoader(exp_dataset, batch_size, shuffle=True, pin_memory=True)\n",
    "results_df = pd.DataFrame(columns=columns_to_use)\n",
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "    states, actions, returns, timesteps = batch\n",
    "    new_action = random.choice([0, 1, 2])\n",
    "\n",
    "    # First check for queue_type\n",
    "    df_qt= df[df['queue_type']== int(states[0][0][0])]\n",
    "    df_ats= df_qt[df_qt['dequeue_action']== int(actions[0])]\n",
    "    print(\"df_ats.shape\",df_ats.shape)\n",
    "    print(\"states[0][0][6]\",states[0][0][6])\n",
    "        # Skip if df_ats is empty\n",
    "    if df_ats.empty:\n",
    "        print(\"df_ats is empty, skipping this batch.\")\n",
    "        continue  # Skip to the next iteration of the loop\n",
    "\n",
    "\n",
    "    datapoint = find_nearest_length(df_ats, float(states[0][0][6]))\n",
    "\n",
    "    if datapoint is None:\n",
    "            print(\"No valid datapoint found, skipping this batch.\")\n",
    "            continue  # Skip to the next iteration if no valid datapoint\n",
    "    \n",
    "    print(\"DataPoint\")\n",
    "    print(type(datapoint))  # Check the type of 'datapoint'\n",
    "\n",
    "\n",
    "    # Convert the selected columns of the datapoint to a DataFrame\n",
    "    datapoint_df = pd.DataFrame([datapoint])\n",
    "\n",
    "    print(datapoint_df.columns)\n",
    "\n",
    "    # Use pd.concat to append the new DataFrame to results_df\n",
    "    results_df = pd.concat([results_df, datapoint_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\",df_ats.shape)\n",
    "    print(\"\",states[0][0][6])\n",
    "    print(\"\",int(actions[0]))\n",
    "    print(\"\",int(states[0][0][0]))\n",
    "    print(\"\",states[0].size())\n",
    "    print(\"\",states[0][0].size())\n",
    "    print(\"\",states[0][0][0].size())\n",
    "    print(\"\",list(states[0][0]))\n",
    "    print(\"Type of first element in states:\", type(states[0]))\n",
    "    print(\"process_batch states type:\",type(states))\n",
    "    break\n",
    "\n",
    "# Save the results DataFrame to a CSV file after the loop\n",
    "results_df.to_csv(\"results.csv\", index=False)\n",
    "print(\"Results saved to results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for step, batch in enumerate(dataloader):\n",
    "    count+=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urllc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
